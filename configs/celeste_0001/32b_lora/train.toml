max_steps = 500

[monitor.wandb]
project = "celeste-0001"

[model]
name = "cosmicoptima/GLM-4-32B-Base-32K"
liger_kernel = true

[model.lora]
enabled = true
rank = 16
alpha = 256.0
dropout = 0.05
target_modules = [
   ".*\\.q_proj$",
   ".*\\.k_proj$", 
   ".*\\.v_proj$",
   ".*\\.o_proj$",
]
trainable_modules = [
   "lm_head$",
   ".*\\.embed_tokens$",
   ".*\\.norm$",
]
merge_on_save = true

[model.ac]
freq = 1

[optim]
lr = 1e-6
max_norm = 0.001
weight_decay = 0.001
type = adamw_4bit

[ckpt]
interval = 100